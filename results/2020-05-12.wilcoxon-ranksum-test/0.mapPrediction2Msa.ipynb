{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "from uniprotRetrieve import uniprotRetrieve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Get twins (Bacteria, any evidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous analysis, \n",
    "a twins directory was generated.\n",
    "In this directory, \n",
    "cytoplasm / secretome twims were listed in a table for each of the different organisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 776/776 [00:00<00:00, 1838.43it/s]\n"
     ]
    }
   ],
   "source": [
    "DIR=\"../2020-04-06.FindTwinsAnyEvidenceBacteria/3.3.twins/\"\n",
    "TWINS_COMBINED=list()                    # Empty list that will be appended in a loop\n",
    "for FILE in tqdm([F for F in os.listdir(DIR) if F.endswith(\".tab\")]):\n",
    "    \"\"\"\n",
    "    Loop through all the files inside the twins directory.\n",
    "    Each file corresponds to a bacterial organism and inside is a list of twins.\n",
    "    \"\"\"\n",
    "    ORGANISM=FILE.replace(\".tab\",\"\")     # Extract organism from file\n",
    "    FILE_PATH=\"{}{}\".format(DIR,FILE)    # Get full path of FILE\n",
    "    F = open(FILE_PATH)\n",
    "    F.readline()                         # First line is header and can be skipped\n",
    "    for LINE in F:\n",
    "        CYTOPLASM_PROTEIN, PERIPLASM_PROTEIN = LINE.strip().split(\"\\t\")\n",
    "        TWINS_COMBINED.append((CYTOPLASM_PROTEIN, PERIPLASM_PROTEIN, ORGANISM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cytoplasm</th>\n",
       "      <th>Periplasm</th>\n",
       "      <th>Organism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A5I0AHK7</td>\n",
       "      <td>A0A5I0AM00</td>\n",
       "      <td>Salmonella_enterica_subsp._enterica_serovar_Vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E6BT71</td>\n",
       "      <td>E6BLU6</td>\n",
       "      <td>Escherichia_coli_MS_85-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A5I5GAJ9</td>\n",
       "      <td>A0A5I5G9G4</td>\n",
       "      <td>Salmonella_enterica_subsp._enterica_serovar_Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D2AA92</td>\n",
       "      <td>D2ADI4</td>\n",
       "      <td>Shigella_flexneri_serotype_X_strain_2002017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A5H5RFJ5</td>\n",
       "      <td>A0A5H6V778</td>\n",
       "      <td>Salmonella_enterica_subsp._enterica_serovar_Bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31160</th>\n",
       "      <td>A0A3T3G9X3</td>\n",
       "      <td>A0A3T3G349</td>\n",
       "      <td>Salmonella_enterica_subsp._enterica_serovar_Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31161</th>\n",
       "      <td>A0A080J5A2</td>\n",
       "      <td>A0A080J791</td>\n",
       "      <td>Escherichia_coli_1-250-04_S3_C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31162</th>\n",
       "      <td>A0A5I1I569</td>\n",
       "      <td>A0A5H7PWL6</td>\n",
       "      <td>Salmonella_enterica_subsp._enterica_serovar_Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31163</th>\n",
       "      <td>D8E624</td>\n",
       "      <td>D8E319</td>\n",
       "      <td>Escherichia_coli_MS_119-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31164</th>\n",
       "      <td>A0A5F1DXY5</td>\n",
       "      <td>A0A5F1E5W7</td>\n",
       "      <td>Escherichia_sp._E4930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31165 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cytoplasm   Periplasm  \\\n",
       "0      A0A5I0AHK7  A0A5I0AM00   \n",
       "1          E6BT71      E6BLU6   \n",
       "2      A0A5I5GAJ9  A0A5I5G9G4   \n",
       "3          D2AA92      D2ADI4   \n",
       "4      A0A5H5RFJ5  A0A5H6V778   \n",
       "...           ...         ...   \n",
       "31160  A0A3T3G9X3  A0A3T3G349   \n",
       "31161  A0A080J5A2  A0A080J791   \n",
       "31162  A0A5I1I569  A0A5H7PWL6   \n",
       "31163      D8E624      D8E319   \n",
       "31164  A0A5F1DXY5  A0A5F1E5W7   \n",
       "\n",
       "                                                Organism  \n",
       "0      Salmonella_enterica_subsp._enterica_serovar_Vi...  \n",
       "1                               Escherichia_coli_MS_85-1  \n",
       "2      Salmonella_enterica_subsp._enterica_serovar_Ne...  \n",
       "3            Shigella_flexneri_serotype_X_strain_2002017  \n",
       "4      Salmonella_enterica_subsp._enterica_serovar_Bu...  \n",
       "...                                                  ...  \n",
       "31160  Salmonella_enterica_subsp._enterica_serovar_Br...  \n",
       "31161                    Escherichia_coli_1-250-04_S3_C2  \n",
       "31162  Salmonella_enterica_subsp._enterica_serovar_Su...  \n",
       "31163                          Escherichia_coli_MS_119-7  \n",
       "31164                              Escherichia_sp._E4930  \n",
       "\n",
       "[31165 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TWINS = pd.DataFrame(TWINS_COMBINED, columns=[\"Cytoplasm\", \"Periplasm\", \"Organism\"])\n",
    "TWINS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 31.165 possible twins.\n",
    "In this groups there are related proteins though.\n",
    "It could be that cytoplasmic protein A and B are closely related. \n",
    "If they form a Twin with C,D en E, this will result in 6 pairs:\n",
    "(AC, AD, AE, BC, BD, BE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1325"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CYTOPLASM_UNIQUE = TWINS[\"Cytoplasm\"].unique()\n",
    "len(CYTOPLASM_UNIQUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There 1325 unique cytoplasmic proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1902"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERIPLASM_UNIQUE = TWINS[\"Periplasm\"].unique()\n",
    "len(PERIPLASM_UNIQUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1902 unique periplasmic proteins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Look up signal peptide positions for periplasmic proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare amino acids of periplasmic and cytoplasmic proteins, \n",
    "the signal peptide should be cut of.\n",
    "For that it is necessary to now where the start and end position of the signal peptide.\n",
    "To achieve this goal in a quick and efficient manner,\n",
    "the uniprot mapper API will be used to map the uniprot Ids to themselves.\n",
    "In the protein a group ID is generated (which is remembered by uniprot for one week.\n",
    "With this group Id, a usual uniprot search query can be performed to retrieve the signal peptide information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yourlist:M20200512216DA2B77BFBD2E6699CA9B6D1C41EB287BC8CC'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Put parameters that describe what you want to request from the mapper \n",
    "in a dictionary.\"\"\"\n",
    "PARAMS={\n",
    "        \"from\":\"ACC\",\n",
    "        \"to\":\"ACC\",\n",
    "        \"format\":\"tab\",\n",
    "        \"columns\":\"id\"\n",
    "        }\n",
    "PARAMS[\"query\"]=\"\\n\".join(PERIPLASM_UNIQUE)\n",
    "\n",
    "\"\"\"Encode parameters into a form that can be passed by urllib (use UTF-8 encoding)\"\"\"\n",
    "DATA = urllib.parse.urlencode(PARAMS)\n",
    "DATA = DATA.encode('utf-8')\n",
    "\n",
    "\"\"\"Request mapping information from Uniprot Mapping API\"\"\"\n",
    "URL=\"https://www.uniprot.org/uploadlists/\"\n",
    "REQ = urllib.request.Request(URL, DATA)\n",
    "with urllib.request.urlopen(REQ) as F:\n",
    "    # Only first line needs to be read to get group ID\n",
    "    GROUP_ID = str(F.readline(), 'utf-8').strip().split(\"\\t\")[-1]\n",
    "GROUP_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'periplasm_signal_peptides.tab'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Uniprot search query API to retrieve signal peptide information\n",
    "FILE_NAME=\"periplasm_signal_peptides.tab\"\n",
    "QUERY=GROUP_ID\n",
    "FORMAT=\"tab\"\n",
    "COLUMNS=\"id,feature(SIGNAL)\"\n",
    "uniprotRetrieve(FILE_NAME,query=QUERY,format=FORMAT, columns=COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Periplasm</th>\n",
       "      <th>SP_start</th>\n",
       "      <th>SP_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P00805</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q59635</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q72EC8</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P25718</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q7M827</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>A0A5C6XDI0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>A0A1C4AWP6</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>A0A2U8Y9B8</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>A0A0K9T8F9</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>A0A3Q9U6Z4</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1769 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Periplasm  SP_start  SP_end\n",
       "0         P00805         1      22\n",
       "1         Q59635         1      30\n",
       "2         Q72EC8         1      28\n",
       "3         P25718         1      17\n",
       "4         Q7M827         1      33\n",
       "...          ...       ...     ...\n",
       "1764  A0A5C6XDI0         1      36\n",
       "1765  A0A1C4AWP6         1      26\n",
       "1766  A0A2U8Y9B8         1      30\n",
       "1767  A0A0K9T8F9         1      30\n",
       "1768  A0A3Q9U6Z4         1      34\n",
       "\n",
       "[1769 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map signal peptide info back to twins\n",
    "FILE_NAME=\"periplasm_signal_peptides.tab\"\n",
    "\n",
    "SIGNAL_PEP_START_END=list()\n",
    "\n",
    "F = open(FILE_NAME)\n",
    "for LINE in F:\n",
    "    ID,SIGNAL_PEP_INFO=LINE.split(\"\\t\")\n",
    "    if SIGNAL_PEP_INFO.startswith(\"SIGNAL\"):\n",
    "        START_END=SIGNAL_PEP_INFO.replace(\";\",\"\").split(\" \")[1]\n",
    "        START,END= [int(ELM) for ELM in START_END.split(\"..\")]\n",
    "        SIGNAL_PEP_START_END.append((ID,START,END))\n",
    "F.close()\n",
    "    \n",
    "SIGNAL_PEPTIDES = pd.DataFrame(SIGNAL_PEP_START_END, columns=[\"Periplasm\",\"SP_start\",\"SP_end\"])\n",
    "SIGNAL_PEPTIDES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add information to TWINS dataframe and write to file\n",
    "TWINS_WITH_SP = pd.merge(TWINS, SIGNAL_PEPTIDES, on=\"Periplasm\")\n",
    "FILE_NAME=\"twins_with_org_sp.tab\"\n",
    "TWINS_WITH_SP.to_csv(FILE_NAME,sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Retrieve MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMSA(file):\n",
    "    \"\"\"\n",
    "    Reads MSA file in fasta format and return dictionary:\n",
    "        key: protein ID\n",
    "        value: gabbed sequence\n",
    "    \"\"\"\n",
    "    with open(file) as f:\n",
    "        lines = [line.strip() for line in f.readlines()]\n",
    "    msa=dict()\n",
    "    for line in lines:\n",
    "        if line.startswith(\">\"):\n",
    "            # generate new key for new proteinId\n",
    "            Id=line.replace(\">\",\"\")\n",
    "            msa[Id]=\"\"\n",
    "        else:\n",
    "            # add sequence to entry\n",
    "            msa[Id]+=line\n",
    "    return msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 386/386 [00:00<00:00, 1092.51it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Retrieve all the MSA sequences and group them by main protein\"\"\"\n",
    "DIR=\"../2020-04-06.FindTwinsAnyEvidenceBacteria/4.7.clustalOmega/\"\n",
    "ALL_MSA=dict()\n",
    "for FILE in tqdm([F for F in os.listdir(DIR) if F.endswith(\".fasta\")]):\n",
    "    FILE_PATH=\"{}{}\".format(DIR,FILE)\n",
    "    ID=FILE.replace(\".MSA.fasta\",\"\")\n",
    "    ALL_MSA[ID]=readMSA(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187, 199)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into cytoplasmic and periplasmic groups\n",
    "CYTOPLASMIC_MSA = {ID:VALUE for ID,VALUE in ALL_MSA.items() if ID in CYTOPLASM_UNIQUE}\n",
    "PERIPLASMIC_MSA = {ID:VALUE for ID,VALUE in ALL_MSA.items() if ID in PERIPLASM_UNIQUE}\n",
    "len(CYTOPLASMIC_MSA), len(PERIPLASMIC_MSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Retrieve Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPredictions(file):\n",
    "    \"\"\"\n",
    "    Reads prediction file and returns dictionary\n",
    "        key: protein ID\n",
    "        value: list of predictions\n",
    "    \"\"\"\n",
    "    with open(file) as f:\n",
    "        # Strip lines and leave out empty lines\n",
    "        lines = [line.strip() for line in f.readlines() if len(line.strip())>0]\n",
    "    predictions=dict()\n",
    "    for line in lines:\n",
    "        if line.startswith(\"* for \"):\n",
    "            # Extract Id from header and assign to dictionary\n",
    "            Id=line.replace(\"* for \",\"\").replace(\" \",\"\").replace(\"*\",\"\")\n",
    "            predictions[Id]=list()\n",
    "        elif line.startswith(\"*\"):\n",
    "            # Skip lines of the headers\n",
    "            pass\n",
    "        else:\n",
    "            residue, pred_raw = line.replace(\" \",\"\").split(\"\\t\")\n",
    "            pred=float(pred_raw)\n",
    "            predictions[Id].append((residue,pred))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 386/386 [01:52<00:00,  3.42it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Retrieve all the MSA predictions and group them by main protein\"\"\"\n",
    "DIR=\"../2020-04-20.efoldMinePrediction/AnyEvidenceBacteria\"\n",
    "PREDICTIONS_ALL=dict()\n",
    "for ID in tqdm(os.listdir(DIR)):\n",
    "    SUBDIR=\"{}/{}\".format(DIR,ID)\n",
    "    PREDICTIONS_ALL[ID]=dict()\n",
    "    for FILE in [F for F in os.listdir(SUBDIR) if F!=\".ipynb_checkpoints\"]:\n",
    "        FILE_PATH=\"{}/{}\".format(SUBDIR,FILE)\n",
    "        PRED_TYPE=FILE.replace(\".pred\",\"\").split(\"_\")[-1]\n",
    "        PREDICTIONS_ALL[ID][PRED_TYPE]=readPredictions(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 386/386 [00:00<00:00, 8467.31it/s]\n",
      "100%|██████████| 386/386 [00:00<00:00, 6552.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(187, 199)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into cytoplasmic and periplasmic groups\n",
    "# This filles up the memory very close to 8GB\n",
    "CYTOPLASMIC_PREDICTIONS = {ID:VALUE for ID,VALUE in tqdm(PREDICTIONS_ALL.items()) if ID in CYTOPLASM_UNIQUE}\n",
    "PERIPLASMIC_PREDICTIONS = {ID:VALUE for ID,VALUE in tqdm(PREDICTIONS_ALL.items()) if ID in PERIPLASM_UNIQUE}\n",
    "len(CYTOPLASMIC_PREDICTIONS), len(PERIPLASMIC_PREDICTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 Map Predictions to MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapPredictions(predictions, msa):\n",
    "    \"\"\"\n",
    "    Uses predictions dictionary and msa dictionary as input and returns mapped predictions dictionary:\n",
    "        key:protein ID\n",
    "        value: mapped prediction\n",
    "    \"\"\"\n",
    "    def map(gabbedSequence, predictionSequence, gab=\"-\"):\n",
    "        \"\"\"\n",
    "        Map one gabbed MSA sequence to a prediction sequence.\n",
    "            Returns mapped prediction sequence with np.nan values at the gabs\n",
    "        \"\"\"\n",
    "        if len(gabbedSequence.replace(gab,\"\"))!=len(predictionSequence):\n",
    "            print(\"There is an unequal amount of predictions and residues in the MSA\")\n",
    "            raise\n",
    "        # dummy so that there is no out of range ERROR\n",
    "        predictionSequence=predictionSequence[:]+[(\"dummy\",\"dummy\")]\n",
    "        \"\"\"This list will be filled up:\n",
    "            * a prediction value if there is a residue at the position\n",
    "            * np.nan value if there is no residue \"\"\"\n",
    "        gabbedPredictionSequence=list()\n",
    "        \"\"\"Integer of where we are in prediction Sequence\n",
    "        Everytime we encounter a residue in the MSA sequence, this value will go up with one\"\"\"\n",
    "        iPredictionSequence=0\n",
    "        for res in gabbedSequence:\n",
    "            predictionRes=predictionSequence[iPredictionSequence][0]\n",
    "            predictionValue=predictionSequence[iPredictionSequence][1]\n",
    "            if res==gab:\n",
    "                \"\"\"Gabs are mapped to np.nan values\"\"\"\n",
    "                gabbedPredictionSequence.append(np.nan)\n",
    "            elif res!=predictionRes:\n",
    "                print(\"residue of prediction and residue in MSA should be the same\")\n",
    "                raise\n",
    "            else:\n",
    "                \"\"\"Residues are mapped to there prediction\"\"\"\n",
    "                gabbedPredictionSequence.append(predictionValue)\n",
    "                iPredictionSequence+=1\n",
    "        return gabbedPredictionSequence\n",
    "    \n",
    "    \"\"\"Identifieres in MSA and predictions should be the same:\n",
    "        Mapping will only happen for those Identifiers that occur in both the MSA and prediction set\"\"\"\n",
    "    msaIds = set(msa.keys())\n",
    "    mappedPredictions=dict()\n",
    "    for predictionType in predictions.keys():\n",
    "        predictionIds=set(predictions[predictionType].keys())\n",
    "        Ids=msaIds&predictionIds\n",
    "        for Id in Ids:\n",
    "            if Id not in mappedPredictions.keys():\n",
    "                mappedPredictions[Id]=dict()\n",
    "            msaSequence=msa[Id]\n",
    "            predictionSequence=predictions[predictionType][Id]\n",
    "            mappedPredictions[Id][\"msa\"]=msaSequence\n",
    "            mappedPredictions[Id][predictionType]=map(msaSequence,predictionSequence)\n",
    "    \n",
    "    '''\n",
    "    for predictionType in predictions[id1].keys():\n",
    "        predictionIds = set(predictions[predictionType].keys())\n",
    "        print(predictionIds)\n",
    "        msaIds = set(msa.keys())\n",
    "        if msaIds!=predictionIds:\n",
    "            print(\"\"\"provided protein IDs for MSA not the same as IDs for predictions, \n",
    "                  taking the intersection of both sets\"\"\")\n",
    "            ids=sorted(predictionIds&msaIds)\n",
    "        else:\n",
    "            ids=sorted(msaIds)\n",
    "        mappedPredictions=dict()\n",
    "        for Id in ids:\n",
    "            msaSequence=msa[Id]\n",
    "            predictionSequence=predictions[predictionType][Id]\n",
    "            mappedPredictions[Id]=dict()\n",
    "            mappedPredictions[Id][\"msa\"]=msaSequence\n",
    "            mappedPredictions[Id][predictionType]=map(msaSequence,predictionSequence)\n",
    "    '''\n",
    "    return mappedPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 386/386 [01:05<00:00,  5.86it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Map all the predictions to their MSA\n",
    "Because it is not possible to hold everythin and all previous in memory at the same time.\n",
    "it will be written sequentially to files\"\"\"\n",
    "def writeMappedMsaPrediction(fileName, mappedMsaPrediction):\n",
    "    \"\"\"\n",
    "    Takes as input dictionary with mapped MSA predictions and filename.\n",
    "    Writes to file.\n",
    "    \"\"\"\n",
    "    output=open(fileName,\"w\")\n",
    "    for Id,values in mappedMsaPrediction.items():\n",
    "        output.write(\">{}\\n\".format(Id))\n",
    "        for predictionKey,predictionValue in values.items():\n",
    "            toWrite=\"{}\\t{}\\n\".format(predictionKey,\" \".join([str(elm) for elm in list(predictionValue)]))\n",
    "            output.write(toWrite)\n",
    "    output.close()\n",
    "\n",
    "OUTPUT_DIR=\"mappedPredictions\"    \n",
    "for ID in tqdm(ALL_MSA.keys()):\n",
    "    MAPPED_MSA_PREDICTION = mapPredictions(PREDICTIONS_ALL[ID], ALL_MSA[ID])\n",
    "    OUTPUT_FILE=\"{}/{}_mapped_predictions.txt\".format(OUTPUT_DIR,ID)\n",
    "    writeMappedMsaPrediction(OUTPUT_FILE,MAPPED_MSA_PREDICTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.6 Sort predictions per Twin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid redundancy in the dataset,\n",
    "only one Twin was taken if multiple were available for similar proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "CYTOPLASM_WITH_MSA=pd.DataFrame(CYTOPLASMIC_MSA.keys(),columns=[\"Cytoplasm\"])\n",
    "PERIPLASM_WITH_MSA=pd.DataFrame(PERIPLASMIC_MSA.keys(),columns=[\"Periplasm\"])\n",
    "TWINS_UNIQUE_WITH_MSA = TWINS_WITH_SP\\\n",
    ".merge(CYTOPLASM_WITH_MSA,on=\"Cytoplasm\")\\\n",
    ".merge(PERIPLASM_WITH_MSA,on=\"Periplasm\")\\\n",
    ".groupby([\"Cytoplasm\"],as_index=False)\\\n",
    ".first()\\\n",
    ".groupby([\"Periplasm\"],as_index=False)\\\n",
    ".first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWINS_UNIQUE_WITH_MSA.to_csv(\"twins_unique_with_msa.tab\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
